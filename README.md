
# ğŸŒŸ Projet de RÃ©seau de Neurones ğŸŒŸ

## ğŸ“ Vue d'ensemble

Ce projet est une implÃ©mentation d'un rÃ©seau de neurones Ã  partir de zÃ©ro en utilisant Python. L'implÃ©mentation inclut des couches, des neurones, des fonctions d'activation et des fonctions de perte personnalisÃ©es. Le projet comprend Ã©galement une interface graphique (GUI) pour configurer et entraÃ®ner le rÃ©seau de neurones, ainsi qu'une interface en ligne de commande (CLI) pour l'exÃ©cution en ligne de commande.

## âœ¨ FonctionnalitÃ©s

- ğŸš€ **Multiples fonctions d'activation** : ReLU, Tanh, Sigmoid, Leaky ReLU
- ğŸ“‰ **Fonction de perte** : Erreur Quadratique Moyenne (MSE)
- ğŸ”— **Couches entiÃ¨rement connectÃ©es**
- ğŸ› ï¸ **Facile Ã  utiliser et Ã  Ã©tendre**


## ğŸ“¦ Installation

Pour exÃ©cuter le projet, vous devez avoir Python installÃ©. Vous pouvez installer les dÃ©pendances requises en utilisant la commande suivante :

```bash
pip install -r requirements.txt
```

## ğŸ—‚ï¸ Structure du Projet

Le projet est organisÃ© en plusieurs modules Python :

- `activation_functions.py` : Contient diverses fonctions d'activation et leurs dÃ©rivÃ©es.
- `csv_dataloader.py` : GÃ¨re le chargement et la validation des donnÃ©es Ã  partir de fichiers CSV.
- `loss_functions.py` : Contient des fonctions de perte et leurs dÃ©rivÃ©es.
- `neural_layer.py` : DÃ©finit les couches du rÃ©seau de neurones.
- `neural_network.py` : ImplÃ©mente le rÃ©seau de neurones.
- `neuron.py` : DÃ©finit les neurones individuels.
- `main_window.py` : ImplÃ©mentation de l'interface graphique pour configurer et entraÃ®ner le rÃ©seau de neurones.
- `training_thread.py` : GÃ¨re le processus d'entraÃ®nement dans un thread sÃ©parÃ© pour l'interface graphique.
- `runner.py` : Contient diffÃ©rents modes d'exÃ©cution (CLI, GUI, TEST).
- `main.py` : Point d'entrÃ©e pour exÃ©cuter le projet.

## âš™ï¸ Configuration du RÃ©seau de Neurones

### ParamÃ¨tres

- `input_size` : Nombre de caractÃ©ristiques d'entrÃ©e.
- `output_size` : Nombre de caractÃ©ristiques de sortie.
- `hidden_layers` : Nombre de couches cachÃ©es dans le rÃ©seau.
- `neurons_per_layer` : Nombre de neurones par couche cachÃ©e.
- `activation_function` : Fonction d'activation Ã  utiliser (RELU, TANH, SIGMOID, LEAKY_RELU).
- `loss_function` : Fonction de perte Ã  utiliser (actuellement, seule MSE est implÃ©mentÃ©e).
- `epochs` : Nombre d'itÃ©rations d'entraÃ®nement.
- `learning_rate` : Taux d'apprentissage.

### âš¡ Fonctions d'Activation

Le framework supporte les fonctions d'activation suivantes :

1. **ReLU (Rectified Linear Unit)**
    - **Sortie** : [0, +âˆ)
    - **DÃ©rivÃ©e** : 1 si x > 0, sinon 0
    - **Cas d'utilisation** : Capturer les non-linÃ©aritÃ©s, Ã©viter le problÃ¨me de gradient vanishing

2. **Tanh (Tangente Hyperbolique)**
    - **Sortie** : [-1, 1]
    - **DÃ©rivÃ©e** : 1 - tanh(x)^2
    - **Cas d'utilisation** : Normaliser les entrÃ©es entre [-1, 1], souvent utilisÃ© dans les couches cachÃ©es

3. **SigmoÃ¯de**
    - **Sortie** : (0, 1)
    - **DÃ©rivÃ©e** : Ïƒ(x) * (1 - Ïƒ(x)), oÃ¹ Ïƒ(x) est la fonction sigmoÃ¯de
    - **Cas d'utilisation** : Normaliser les sorties, souvent utilisÃ© pour des problÃ¨mes de classification binaire

4. **Leaky ReLU**
    - **Sortie** : (-âˆ, +âˆ) (mais principalement [0, +âˆ) avec une petite pente nÃ©gative)
    - **DÃ©rivÃ©e** : 1 si x > 0, sinon Î± (souvent Î± = 0.01)
    - **Cas d'utilisation** : Ã‰viter les neurones morts (problÃ¨me de gradient mort)

### ğŸ¯ Obtenir de Bons RÃ©sultats

Pour obtenir de bons rÃ©sultats pour diffÃ©rents types de donnÃ©es, considÃ©rez les conseils suivants :

1. **ğŸ“Š Normalisation des DonnÃ©es** : Assurez-vous que vos donnÃ©es d'entrÃ©e sont normalisÃ©es. Par exemple, Ã©chellez vos caractÃ©ristiques pour avoir une moyenne nulle et une variance unitaire.
2. **âš™ï¸ Fonction d'Activation** : Choisissez la fonction d'activation qui convient le mieux Ã  votre problÃ¨me. Par exemple, utilisez Sigmoid ou Tanh pour les tÃ¢ches de classification binaire et ReLU pour les rÃ©seaux profonds.
3. **ğŸ—ï¸ Architecture du RÃ©seau** : ExpÃ©rimentez avec le nombre de couches et de neurones par couche. Les tÃ¢ches plus complexes peuvent nÃ©cessiter des rÃ©seaux plus profonds.
4. **ğŸ§  Taux d'Apprentissage** : Ajustez le taux d'apprentissage. Un taux trop Ã©levÃ© peut entraÃ®ner une convergence trop rapide vers une solution sous-optimale, tandis qu'un taux trop bas peut rendre le processus d'entraÃ®nement trop lent.
5. **â³ Ã‰poques** : EntraÃ®nez pendant un nombre suffisant d'Ã©poques. Cependant, mÃ©fiez-vous du surapprentissage ; envisagez d'utiliser l'arrÃªt prÃ©coce ou la validation croisÃ©e pour trouver le nombre optimal d'Ã©poques.


## ğŸš€ EntraÃ®nement et Test

### Format des DonnÃ©es d'EntraÃ®nement

Les donnÃ©es d'entraÃ®nement doivent Ãªtre au format CSV avec les caractÃ©ristiques d'entrÃ©e et les valeurs de sortie. Les caractÃ©ristiques d'entrÃ©e doivent Ãªtre prÃ©fixÃ©es par 'Input' et les caractÃ©ristiques de sortie par 'Output'.

Exemple de fichier CSV d'entraÃ®nement (`train_data_relu.csv`) :

```csv
Input1,Input2,Output
0,0,0
0,1,1
1,0,1
1,1,0
```

### Format des DonnÃ©es de Test

Les donnÃ©es de test doivent suivre le mÃªme format que les donnÃ©es d'entraÃ®nement, mais sans les valeurs de sortie.

Exemple de fichier CSV de test (`test_data_relu.csv`) :

```csv
Input1,Input2
0,0
0,1
1,0
1,1
```

## ğŸ’» Utilisation

### Interface Graphique (GUI)

Pour lancer l'application avec l'interface graphique, exÃ©cutez le script `main.py` :

```bash
python main.py
```

L'application GUI permet de configurer les paramÃ¨tres du rÃ©seau de neurones, de charger des fichiers CSV pour l'entraÃ®nement et les prÃ©dictions, et de visualiser la structure du rÃ©seau.

### Ligne de Commande (CLI)

Pour exÃ©cuter l'application en ligne de commande, modifiez le script `main.py` pour utiliser le mode CLI et exÃ©cutez-le :

```bash
python main.py
```

Exemple d'exÃ©cution en ligne de commande avec les donnÃ©es XOR :

```python
def cli():
    x_train = np.array([
        [[0, 0]],
        [[0, 1]],
        [[1, 0]],
        [[1, 1]]
    ])
    y_train = np.array([[0], [1], [1], [0]])

    print("X data:", x_train)
    print("Y data:", y_train)

    input_size = 2
    output_size = 1
    hidden_layers = 1
    neurons_per_layer = 2
    activation_function = ActivationFunction.LEAKY_RELU

    net = NeuralNetwork(input_size, output_size, hidden_layers, neurons_per_layer, activation_function, mse, mse_prime)
    net.fit(x_train, y_train, epochs=100000, learning_rate=0.1)

    out = net.predict(x_train)
    print(out)
```

Fichier `requirements.txt` :

```text
pandas~=2.2.2
PySide6~=6.7.2
numpy~=2.0.0
```


Des fichiers de test sont inclus dans le dossier `tests/datasets` du projet, et les configurations + rÃ©sultats des tests sont stockÃ©s dans le dossier `tests/results`.
